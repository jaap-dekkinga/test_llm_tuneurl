<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TuneURL Audio Classifier</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.min.js"></script>
    <script src="https://unpkg.com/meyda@5.6.0/dist/web/meyda.min.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        .animate-spin {
            animation: spin 1s linear infinite;
        }
    </style>
</head>
<body class="bg-gradient-to-br from-blue-50 to-indigo-100 min-h-screen">
    <div class="container mx-auto p-8 max-w-4xl">
        <!-- Header -->
        <div class="text-center mb-8">
            <h1 class="text-4xl font-bold text-gray-800 mb-2">
                ðŸŽµ TuneURL Audio Classifier
            </h1>
            <p class="text-gray-600">
                Upload an audio file to detect if it contains TuneURL content
            </p>
        </div>

        <!-- Main Card -->
        <div class="bg-white rounded-xl shadow-lg p-8 mb-6">
            <!-- Upload Area -->
            <div id="dropZone" class="border-2 border-dashed border-gray-300 rounded-lg p-12 text-center hover:border-indigo-500 transition-colors cursor-pointer">
                <svg class="mx-auto h-16 w-16 text-gray-400 mb-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12" />
                </svg>
                <p class="text-lg text-gray-600 mb-2">
                    Drop your audio file here or click to browse
                </p>
                <p class="text-sm text-gray-500">
                    Supports WAV, MP3, and other audio formats
                </p>
                <input type="file" id="fileInput" accept="audio/*" class="hidden" />
            </div>

            <!-- File Preview -->
            <div id="filePreview" class="hidden mt-6 p-4 bg-gray-50 rounded-lg">
                <div class="flex items-center justify-between mb-3">
                    <div class="flex items-center space-x-3">
                        <svg class="h-6 w-6 text-indigo-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15.536 8.464a5 5 0 010 7.072m2.828-9.9a9 9 0 010 12.728M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z" />
                        </svg>
                        <div>
                            <p id="fileName" class="font-medium text-gray-800"></p>
                            <p id="fileSize" class="text-sm text-gray-500"></p>
                        </div>
                    </div>
                </div>
                <audio id="audioPlayer" controls class="w-full mt-4"></audio>
            </div>

            <!-- Error Message -->
            <div id="errorMessage" class="hidden mt-6 p-4 bg-red-50 border border-red-200 rounded-lg">
                <div class="flex items-start space-x-3">
                    <svg class="h-6 w-6 text-red-600 flex-shrink-0 mt-0.5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4m0 4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
                    </svg>
                    <div>
                        <p class="font-medium text-red-800">Error</p>
                        <p id="errorText" class="text-sm text-red-600"></p>
                    </div>
                </div>
            </div>

            <!-- Processing Indicator -->
            <div id="processingIndicator" class="hidden mt-6 p-6 bg-blue-50 rounded-lg text-center">
                <svg class="h-8 w-8 text-blue-600 animate-spin mx-auto mb-3" fill="none" viewBox="0 0 24 24">
                    <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                    <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                </svg>
                <p class="text-blue-800 font-medium">Processing audio...</p>
                <p class="text-sm text-blue-600 mt-1" id="processingStep">Extracting features</p>
            </div>

            <!-- Results -->
            <div id="results" class="hidden mt-6 p-6 bg-gradient-to-br from-indigo-50 to-purple-50 rounded-lg">
                <div class="flex items-center justify-center mb-4">
                    <svg id="resultIcon" class="h-12 w-12" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7" />
                    </svg>
                </div>
                
                <h3 id="resultTitle" class="text-2xl font-bold text-center mb-4"></h3>

                <div class="space-y-3">
                    <div class="bg-white rounded-lg p-4">
                        <div class="flex justify-between items-center mb-2">
                            <span class="text-gray-700 font-medium">TuneURL Probability</span>
                            <span id="tuneURLProb" class="text-lg font-bold text-indigo-600">0%</span>
                        </div>
                        <div class="w-full bg-gray-200 rounded-full h-3">
                            <div id="tuneURLBar" class="bg-gradient-to-r from-indigo-500 to-purple-600 h-3 rounded-full transition-all duration-500" style="width: 0%"></div>
                        </div>
                    </div>

                    <div class="bg-white rounded-lg p-4">
                        <div class="flex justify-between items-center mb-2">
                            <span class="text-gray-700 font-medium">Not TuneURL Probability</span>
                            <span id="notTuneURLProb" class="text-lg font-bold text-gray-600">0%</span>
                        </div>
                        <div class="w-full bg-gray-200 rounded-full h-3">
                            <div id="notTuneURLBar" class="bg-gradient-to-r from-gray-400 to-gray-600 h-3 rounded-full transition-all duration-500" style="width: 0%"></div>
                        </div>
                    </div>
                </div>

                <p class="text-sm text-gray-600 text-center mt-4">
                    Threshold: 0.1 (10%) | Model: TuneURL Classifier v2500
                </p>
            </div>
        </div>

        <!-- Info Card -->
        <div class="bg-white rounded-xl shadow-lg p-6">
            <h3 class="text-lg font-bold text-gray-800 mb-3">About This Classifier</h3>
            <p class="text-gray-600 text-sm mb-2">
                This model uses a neural network trained on audio features (13 MFCCs, spectral centroid, 12 chroma features, and RMS energy) 
                to detect TuneURL content in audio files.
            </p>
            <p class="text-gray-600 text-sm">
                <strong>Model Performance:</strong> ~98% test accuracy with optimized threshold tuning.
            </p>
            <p class="text-gray-600 text-sm mt-2">
                <strong>Note:</strong> Make sure to upload your <code>tuneurl_model_web2500.onnx</code> and <code>scaler_full2500.json</code> files to the same directory as this HTML file.
            </p>
        </div>
    </div>

    <script>
        let session = null;
        let scaler = null;
        const THRESHOLD = 0.1;

        // Initialize ONNX Runtime and load model
        async function initializeModel() {
            try {
                if (session && scaler) return true;

                updateProcessingStep('Loading model...');

                // Load scaler parameters
                const scalerResponse = await fetch('scaler_full2500.json');
                scaler = await scalerResponse.json();

                // Load ONNX model
                session = await ort.InferenceSession.create('tuneurl_model_web2500.onnx');

                console.log('Model loaded successfully');
                return true;
            } catch (error) {
                console.error('Model initialization error:', error);
                showError('Failed to load model. Make sure tuneurl_model_web2500.onnx and scaler_full2500.json are in the same directory.');
                return false;
            }
        }

        // Extract 112-dimensional feature vector using Meyda
        function extractFeatures(audioBuffer) {
            const sampleRate = audioBuffer.sampleRate;
            const audioData = audioBuffer.getChannelData(0);
            
            // Parameters matching your notebook
            const hopSize = 1024;
            const bufferSize = 2048;
            const numFrames = Math.floor((audioData.length - bufferSize) / hopSize);
            
            // Features to extract: 12 chroma + 13 mfcc + spectral centroid + rms = 27 per frame
            const chromaFeatures = [];
            const mfccFeatures = [];
            const centroidFeatures = [];
            const rmsFeatures = [];

            // Extract features for each frame
            for (let i = 0; i < numFrames && i < 50; i++) {
                const start = i * hopSize;
                const frame = audioData.slice(start, start + bufferSize);
                
                const features = Meyda.extract([
                    'chroma',
                    'mfcc',
                    'spectralCentroid',
                    'rms'
                ], frame, {
                    sampleRate: sampleRate,
                    bufferSize: bufferSize,
                    numberOfMFCCCoefficients: 13
                });

                if (features.chroma) chromaFeatures.push(features.chroma);
                if (features.mfcc) mfccFeatures.push(features.mfcc);
                if (features.spectralCentroid) centroidFeatures.push(features.spectralCentroid);
                if (features.rms) rmsFeatures.push(features.rms);
            }

            // Aggregate features: mean and std
            const featureVector = new Float32Array(112);
            let idx = 0;

            // Chroma mean (12) + std (12) = 24
            const chromaMean = calculateMean(chromaFeatures);
            const chromaStd = calculateStd(chromaFeatures);
            for (let i = 0; i < 12; i++) featureVector[idx++] = chromaMean[i];
            for (let i = 0; i < 12; i++) featureVector[idx++] = chromaStd[i];

            // MFCC mean (13) + std (13) = 26
            const mfccMean = calculateMean(mfccFeatures);
            const mfccStd = calculateStd(mfccFeatures);
            for (let i = 0; i < 13; i++) featureVector[idx++] = mfccMean[i];
            for (let i = 0; i < 13; i++) featureVector[idx++] = mfccStd[i];

            // Centroid mean (1) + std (1) = 2
            featureVector[idx++] = calculateScalarMean(centroidFeatures);
            featureVector[idx++] = calculateScalarStd(centroidFeatures);

            // RMS mean (1) + std (1) = 2
            featureVector[idx++] = calculateScalarMean(rmsFeatures);
            featureVector[idx++] = calculateScalarStd(rmsFeatures);

            // Pad remaining to 112
            while (idx < 112) {
                featureVector[idx++] = 0;
            }

            return featureVector;
        }

        // Helper functions for feature aggregation
        function calculateMean(features) {
            if (!features || features.length === 0) return new Array(12).fill(0);
            const numFeatures = features[0].length;
            const means = new Array(numFeatures).fill(0);
            
            for (const feature of features) {
                for (let i = 0; i < numFeatures; i++) {
                    means[i] += feature[i];
                }
            }
            
            return means.map(sum => sum / features.length);
        }

        function calculateStd(features) {
            if (!features || features.length === 0) return new Array(12).fill(0);
            const means = calculateMean(features);
            const numFeatures = features[0].length;
            const variances = new Array(numFeatures).fill(0);
            
            for (const feature of features) {
                for (let i = 0; i < numFeatures; i++) {
                    variances[i] += Math.pow(feature[i] - means[i], 2);
                }
            }
            
            return variances.map(variance => Math.sqrt(variance / features.length));
        }

        function calculateScalarMean(values) {
            if (!values || values.length === 0) return 0;
            return values.reduce((a, b) => a + b, 0) / values.length;
        }

        function calculateScalarStd(values) {
            if (!values || values.length === 0) return 0;
            const mean = calculateScalarMean(values);
            const variance = values.reduce((acc, val) => acc + Math.pow(val - mean, 2), 0) / values.length;
            return Math.sqrt(variance);
        }

        // Apply StandardScaler normalization
        function applyScaler(features) {
            const normalized = new Float32Array(112);
            for (let i = 0; i < 112; i++) {
                normalized[i] = (features[i] - scaler.mean[i]) / scaler.scale[i];
            }
            return normalized;
        }

        // Process audio file
        async function processAudio(file) {
            try {
                showProcessing();
                hideError();
                hideResults();

                // Initialize model
                updateProcessingStep('Loading model...');
                const initialized = await initializeModel();
                if (!initialized) return;

                // Load audio file
                updateProcessingStep('Loading audio...');
                const arrayBuffer = await file.arrayBuffer();
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

                // Extract features
                updateProcessingStep('Extracting audio features...');
                const features = extractFeatures(audioBuffer);

                // Normalize features
                updateProcessingStep('Normalizing features...');
                const normalizedFeatures = applyScaler(features);

                // Run inference
                updateProcessingStep('Running model inference...');
                const inputTensor = new ort.Tensor('float32', normalizedFeatures, [1, 112]);
                const feeds = { input: inputTensor };
                const results = await session.run(feeds);
                
                // Get predictions (softmax output)
                const predictions = results.output.data;
                const notTuneURLProb = predictions[0];
                const tuneURLProb = predictions[1];
                
                // Apply threshold
                const isTuneURL = tuneURLProb >= THRESHOLD;

                // Display results
                displayResults(isTuneURL, notTuneURLProb, tuneURLProb);

            } catch (error) {
                console.error('Processing error:', error);
                showError(`Error processing audio: ${error.message}`);
            } finally {
                hideProcessing();
            }
        }

        // UI Helper Functions
        function showError(message) {
            document.getElementById('errorMessage').classList.remove('hidden');
            document.getElementById('errorText').textContent = message;
        }

        function hideError() {
            document.getElementById('errorMessage').classList.add('hidden');
        }

        function showProcessing() {
            document.getElementById('processingIndicator').classList.remove('hidden');
        }

        function hideProcessing() {
            document.getElementById('processingIndicator').classList.add('hidden');
        }

        function updateProcessingStep(step) {
            document.getElementById('processingStep').textContent = step;
        }

        function hideResults() {
            document.getElementById('results').classList.add('hidden');
        }

        function displayResults(isTuneURL, notTuneURLProb, tuneURLProb) {
            const resultsDiv = document.getElementById('results');
            const resultIcon = document.getElementById('resultIcon');
            const resultTitle = document.getElementById('resultTitle');

            // Update icon and title
            if (isTuneURL) {
                resultIcon.classList.add('text-green-600');
                resultIcon.classList.remove('text-red-600');
                resultIcon.innerHTML = '<path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7" />';
                resultTitle.textContent = 'TuneURL Detected âœ“';
            } else {
                resultIcon.classList.add('text-red-600');
                resultIcon.classList.remove('text-green-600');
                resultIcon.innerHTML = '<path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" />';
                resultTitle.textContent = 'Not TuneURL âœ—';
            }

            // Update probabilities
            const tuneURLPercent = (tuneURLProb * 100).toFixed(2);
            const notTuneURLPercent = (notTuneURLProb * 100).toFixed(2);

            document.getElementById('tuneURLProb').textContent = `${tuneURLPercent}%`;
            document.getElementById('tuneURLBar').style.width = `${tuneURLPercent}%`;
            
            document.getElementById('notTuneURLProb').textContent = `${notTuneURLPercent}%`;
            document.getElementById('notTuneURLBar').style.width = `${notTuneURLPercent}%`;

            resultsDiv.classList.remove('hidden');
        }

        // File handling
        const dropZone = document.getElementById('dropZone');
        const fileInput = document.getElementById('fileInput');

        dropZone.addEventListener('click', () => fileInput.click());

        dropZone.addEventListener('dragover', (e) => {
            e.preventDefault();
            dropZone.classList.add('border-indigo-500');
        });

        dropZone.addEventListener('dragleave', () => {
            dropZone.classList.remove('border-indigo-500');
        });

        dropZone.addEventListener('drop', (e) => {
            e.preventDefault();
            dropZone.classList.remove('border-indigo-500');
            const file = e.dataTransfer.files[0];
            if (file) handleFile(file);
        });

        fileInput.addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (file) handleFile(file);
        });

        function handleFile(file) {
            if (!file.type.startsWith('audio/')) {
                showError('Please select a valid audio file');
                return;
            }

            hideError();
            hideResults();

            // Show file preview
            const filePreview = document.getElementById('filePreview');
            document.getElementById('fileName').textContent = file.name;
            document.getElementById('fileSize').textContent = `${(file.size / 1024).toFixed(2)} KB`;
            
            const audioPlayer = document.getElementById('audioPlayer');
            audioPlayer.src = URL.createObjectURL(file);
            
            filePreview.classList.remove('hidden');

            // Process the file
            processAudio(file);
        }
    </script>
</body>
</html>
